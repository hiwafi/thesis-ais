\section{Result and Discussion} \label{result}

The result of the research is discussed in this chapter. 
This comprises model validation and how different statistical metrics are used to analyze the model's performance. 

\subsection{Model Evaluation}

The model are tested against four metrics, namely:

\begin{itemize}
    \item $R^2$ : Indicate model fit. Best Score = 1
    \item Explained Variance \verb|EV| : Indicate amount of variance in model. Best Score = 1
    \item Mean Absolute Error \verb|MAE| : Indicate how much error a model makes in its prediction. Best Score = 0
    \item Root Mean Square Error \verb|RMSE| : Same as MAE, more sensitive to outlier. Best Score = 0
    \item Median Absolute Error \verb|MAD| : Check robustness against outlier. Best Score = 1
\end{itemize}

The result is summarized in the following table

\begin{table}[ht]
    \centering
    \resizebox {\textwidth}{!}{\begin{tabular}{ccc}
    \hline
    Model & RFR & DTR \\
    \hline
    $R^2$ & 0.9328181446941499    &0.8526085810220092\\
    EV &   0.932872958708872  &0.8526260247615258  \\
    MAE &0.5546347329650284 &0.8108982427834758 \\
    RMSE  &0.7095480848510665 &1.5566896535262504\\
    MAD    &0.38484635910000087 & 0.5475717149999983\\
    \hline
\end{tabular}}
\caption{Model performance}\label{table1}
\end{table}
 
\begin{lstlisting}[language = Python, caption=Model Evaluation]

    def predict_y(x_test,model_type):
        y_predicted = model_type.predict(x_test)
        return y_predicted
    
    def display_scores(x_test,y_test,model_type):
        from sklearn.metrics import explained_variance_score,mean_absolute_error,mean_squared_error,median_absolute_error
        y_predicted = model_type.predict(x_test)
        print("R^2 score (Indicate model fit. Best Score = 1):", model_type.score(x_test,y_test))
        print("Explained Variance EV (Indicate amount of variance in model. Best Score = 1):", explained_variance_score(y_test,y_predicted))
        print("Mean Absolute Error MAE (Indicate how much error a model makes in its prediction. Best Score = 0):", mean_absolute_error(y_test,y_predicted))
        print("Root Mean Square Error RMSE (Same as MAE, more sensitive to outlier. Best Score = 0):", mean_squared_error(y_test,y_predicted))
        print("Median Absolute Error MAD (Check robustness against outlier. Best Score = 1):", median_absolute_error(y_test,y_predicted))
    
    y_predicted = predict_y(x_test,model_rfr)
    display_scores(x_test,y_test,model_rfr)
    
\end{lstlisting}
