{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing :\n",
    "<br>\n",
    "Two data sources will be imported <br>\n",
    "-\"AIS_weather_h_rename_copy.csv\" will be used to replace the information for true current direction and true wind direction <br>\n",
    "-The resulting dataframe will be merged with the dataframe from the \"AIS_weather_H_ok2_copy.csv\" <br>\n",
    "-The data of the journey between Ronne and Sassnitz will be omitted <br>\n",
    "-The threshold for the ships manouvering speed will be 5kt (Abebe) <br>\n",
    "- Update 24/6 : Reverted to true current and true wind direction, from feature importance, the feature significance makes more sense with relation to effect of current and wind to ship speed\n",
    "# Update 27/7\n",
    "-Change in methodology, the validation test dataset is removed as model performance is evaluated by means of k fold cross validation. Using 10 fold cross validation means that it will create its own validation dataset<br>\n",
    "-Then the data will be split in 75:25 ratio (maintaining the amount of training data from previous version)\n",
    "- Reason: removing June data completely will compromise the training process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import datetime\n",
    "import pickle\n",
    "import joblib\n",
    "import time \n",
    "\n",
    "\n",
    "# Change font to latex\n",
    "\n",
    "# Parameter to plot in nice latex fonts\n",
    "plt.rcParams.update({\n",
    "\t\"text.usetex\": True,\n",
    "\t\"font.family\": \"serif\",\n",
    "\t\"font.serif\": \"bookman\",\n",
    "\t})\n",
    "\n",
    "# Load the data to the script\n",
    "\n",
    "dfmain = pd.read_csv(\"AIS_weather_H_ok2_copy.csv\",parse_dates=[\"Time\"])\n",
    "dfmain = dfmain[dfmain['LAT'] > 55.04 ]\n",
    "# dfmain = dfmain.dropna()\n",
    "\n",
    "dfpre = pd.read_csv(\"AIS_weather_h_rename_copy.csv\",parse_dates=[\"Time\"])\n",
    "dfpre = dfpre[dfpre['LAT'] > 55.04 ]\n",
    "# dfpre = dfpre.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing datapoints in dataset\n",
    "\n",
    "dfmain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing datapoints in dataset\n",
    "\n",
    "dfpre.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot to show anomalies in thesis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomalies plot\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "plt.sca(axes[0])\n",
    "dfmain['sog'].hist(bins=50,color='black')\n",
    "# Parameter to plot in nice latex fonts\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams.update({\n",
    "\t\"text.usetex\": True,\n",
    "\t\"font.family\": \"serif\",\n",
    "\t\"font.serif\": \"bookman\",\n",
    "\t})\n",
    "plt.grid(linestyle = '--', linewidth = 0.5)\n",
    "plt.xlabel(r\"SOG $[Knots]$\")\n",
    "plt.title(r\"Speed Over Ground (SOG)\", fontsize=13)\n",
    "plt.sca(axes[1])\n",
    "dfmain['Current Speed'].hist(bins=50,color='black')\n",
    "# Parameter to plot in nice latex fonts\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams.update({\n",
    "\t\"text.usetex\": True,\n",
    "\t\"font.family\": \"serif\",\n",
    "\t\"font.serif\": \"bookman\",\n",
    "\t})\n",
    "plt.grid(linestyle = '--', linewidth = 0.5)\n",
    "plt.xlabel(r\"Current Speed $[m/s]$\")\n",
    "plt.title(r\"Current Speed\", fontsize=13)\n",
    "plt.ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of ship's true north wind and current direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all dulplicate feature in dataset \"AIS_weather_h_rename_copy.csv\"\n",
    "\n",
    "dfpre = dfpre.drop(dfpre.columns[[0,1,2,5,6,7,8,9,10,11,12,13,14,15,16,17,18,21,22,23,26]],axis=1)\n",
    "dfpre = dfpre.rename({'Eastward wind': 'eastwind', 'Northward wind': 'northwind',\n",
    "                           'Eastward current': 'eastcurrent', 'Northward current': 'northcurrent',\n",
    "                           'SOG':'sog','COG':'cog','Heading':'heading'},axis=1) \n",
    "dfpre.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing the information for the missing east and north current data\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=50)\n",
    "imputer.fit(dfpre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pre = imputer.transform(dfpre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpre = pd.DataFrame(x_pre, columns=dfpre.columns, index=dfpre.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate current and wind speed\n",
    "\n",
    "dfpre[\"Current Speed\"] = np.sqrt(dfpre[\"eastcurrent\"]**2 + dfpre[\"northcurrent\"]**2)\n",
    "dfpre[\"Wind Speed\"] = np.sqrt(dfpre[\"eastwind\"]**2 + dfpre[\"northwind\"]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the True North wind direction and split them into quadrants\n",
    "\n",
    "condwind = [(dfpre['eastwind']>0) & (dfpre['northwind']<0),\n",
    "            (dfpre['eastwind']<0) & (dfpre['northwind']>0),\n",
    "            (dfpre['eastwind']>0) & (dfpre['northwind']>0)]\n",
    "\n",
    "choicewind = [360 - np.abs(np.rad2deg(np.arctan(dfpre[\"eastwind\"]/dfpre[\"northwind\"]))),\n",
    "              180 - np.abs(np.rad2deg(np.arctan(dfpre[\"eastwind\"]/dfpre[\"northwind\"]))),\n",
    "              270 - np.abs(np.rad2deg(np.arctan(dfpre[\"eastwind\"]/dfpre[\"northwind\"])))]\n",
    "\n",
    "dfpre[\"True North Wind Direction\"] = np.select(condwind, choicewind, \n",
    "                                                np.abs(np.rad2deg(np.arctan(dfpre[\"eastwind\"]/dfpre[\"northwind\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the True North current direction and split them into quadrants\n",
    "\n",
    "condcurr = [(dfpre['eastcurrent']<0) & (dfpre['northcurrent']>0),\n",
    "            (dfpre['eastcurrent']>0) & (dfpre['northcurrent']<0),\n",
    "            (dfpre['eastcurrent']<0) & (dfpre['northcurrent']<0)]\n",
    "\n",
    "choicecurr = [360 - np.abs(np.rad2deg(np.arctan(dfpre[\"eastcurrent\"]/dfpre[\"northcurrent\"]))),\n",
    "              180 - np.abs(np.rad2deg(np.arctan(dfpre[\"eastcurrent\"]/dfpre[\"northcurrent\"]))),\n",
    "              270 - np.abs(np.rad2deg(np.arctan(dfpre[\"eastcurrent\"]/dfpre[\"northcurrent\"])))]\n",
    "\n",
    "dfpre[\"True North Current Direction\"] = np.select(condcurr, choicecurr, \n",
    "                                                np.abs(np.rad2deg(np.arctan(dfpre[\"eastcurrent\"]/dfpre[\"northcurrent\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics of the dataset for true north weather direction\n",
    "\n",
    "dfpre.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop further unecessary feature before meraging to main dataset\n",
    "\n",
    "dfpre = dfpre.drop(['eastwind','northwind','eastcurrent','northcurrent','sog','cog'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the wind speed and current speed from the original dataset as it contains outlier \n",
    "\n",
    "dfmain = dfmain.drop(['Wind Speed','Current Speed'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the the information of true north to main dataset\n",
    "\n",
    "df = pd.concat([dfmain,dfpre],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOG threshold according to Abebe20 and Yan21\n",
    "\n",
    "df = df[df['SOG'] > 5 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of dataset after speed filter\n",
    "\n",
    "print(f\"Length of speed filter dataset {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(df, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-declare that df will be the dataframe used for training \n",
    "\n",
    "df = train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of test dataset\n",
    "\n",
    "print(f\"Length of train dataset {len(train_set)}\")\n",
    "print(f\"Length of test dataset {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary export\n",
    "# df.to_csv(\"AIS_sog_threshold.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary export\n",
    "# df.to_csv(\"AIS_impute_check.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analysis before modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features that have no impact on model training\n",
    "\n",
    "df_ship = df.drop(['Unnamed: 0','Time','LON','LAT','Air density above oceans',\n",
    "                    'Surface pressure','Width','Length'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ship.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming Features \n",
    "\n",
    "df_ship2 = df_ship.rename({'Max wave height': 'waveheight', 'Draught': 'draught',\n",
    "                           'SOG': 'SOG', 'Wind Speed': 'windspeed', \n",
    "                           'True Wind Direction': 'truewinddir','Temperature above oceans' : 'oceantemperature',\n",
    "                           'COG': 'cog', 'Current Speed' : 'curspeed','True Wave Direction' : 'truewavedir',\n",
    "                            'Swell period': 'swellperiod','Wind wave period': 'windwaveperiod','Sea surface temperature': 'surftemp',\n",
    "                            'Combined wind waves and swell height': 'windwaveswellheight','Swell height': 'swellheight','Wind wave height': 'windwaveheight',\n",
    "                            'Heading': 'heading','True Current Direction': 'truecurrentdir','True Swell Direction': 'trueswelldir',\n",
    "                            'True Wind Wave Direction': 'truewindwavedir','Wave period': 'waveperiod',\n",
    "                            'True North Wind Direction' : 'truenorthwinddir' , 'True North Current Direction' : 'truenorthcurrentdir'\n",
    "                           }, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ship2 = df_ship2[['oceantemperature','waveheight','swellperiod','windwaveperiod','waveperiod','surftemp','windwaveswellheight','swellheight','windwaveheight','draught','sog','cog','heading','windspeed','curspeed','truewinddir','truecurrentdir','trueswelldir','truewindwavedir','truewavedir', 'truenorthwinddir' , 'truenorthcurrentdir']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams.update(plt.rcParamsDefault) # Alter default value \n",
    "axes = df_ship.hist(bins=50,figsize=(10,50),color='black',grid=True,layout=(11,2))\n",
    "for ax in axes.flatten():\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation between variables with SOG\n",
    "\n",
    "corr_matrix = df_ship2.corr()\n",
    "print(corr_matrix[\"sog\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop variables such as date from the dataset\n",
    "\n",
    "dfship_corr = df_ship2.drop(df_ship2.columns[[0,5,15,16,17,18,19,20,21]],axis=1)\n",
    "dfship_corr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_heatmap(df,fontsize):\n",
    "    correlations = df.corr()\n",
    "    # Parameter to plot in nice latex fonts\n",
    "    plt.rcParams.update({\n",
    "\t\"text.usetex\": True,\n",
    "\t\"font.family\": \"serif\",\n",
    "\t\"font.serif\": \"bookman\",\n",
    "\t})\n",
    "    colormap = sns.color_palette(\"Reds\")\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    sns.set(font_scale = fontsize)\n",
    "    sns.heatmap(correlations, vmax=1.0, center=0, fmt='.2f',cmap=\"mako\",\n",
    "                square=True, linewidths=.5, annot=True, cbar_kws={\"shrink\": .70})\n",
    "                # ,annot_kws={'fontsize': 12, 'color':'k', 'alpha': 1})\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap of overall dataset\n",
    "\n",
    "df_ship_ovr = df_ship2\n",
    "correlation_heatmap(df_ship_ovr,.7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scientific Justification of HCF:\n",
    "\n",
    "-According to Bitner Gregersen, the wind wave swell height is equal to the square root of the square of swell wave and wind wave. Therefore SWH and WWH is to be dropped.<br>\n",
    "-According to Mori, through wave spectrum, the maximum wave height can be approximated, therefore max wave height can be dropped as well <br>\n",
    "-According to Torsetshaugen, The type of dominating wave (Wind wave/Swell) can be predicted from the significant through an equation which include the significant wave height and a certain threshold, therefore, it is decided that the wind wave period, swell period and consequently the true wind wave direction and true swell direction is to be dropped.<br>\n",
    "-Drop The True Wind and True North direction and replace with the True North direction\n",
    "- Update 24/6 : Decision reverted to drop true directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ship2 = df_ship2.drop(['waveheight','swellheight','windwaveheight',\n",
    "                        'windwaveperiod','swellperiod',\n",
    "                        'truewindwavedir','trueswelldir',\n",
    "                        'truenorthcurrentdir','truenorthwinddir'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap for training feature\n",
    "\n",
    "correlation_heatmap(df_ship2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate how to toggle the display of different elements:\n",
    "# Histogram plot of final features and labels for training\n",
    "\n",
    "fs = 10\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "# Parameter to plot in nice latex fonts\n",
    "plt.rcParams.update({\n",
    "\t\"text.usetex\": True,\n",
    "\t\"font.family\": \"serif\",\n",
    "\t\"font.serif\": \"bookman\",\n",
    "\t})\n",
    "\n",
    "oceantemp = df_ship2['oceantemperature']\n",
    "waveperiod = df_ship2['waveperiod']\n",
    "surftemp = df_ship2['surftemp']\n",
    "sigwave = df_ship2['windwaveswellheight']\n",
    "draught = df_ship2['draught']\n",
    "sog = df_ship2['sog']\n",
    "cog = df_ship2['cog']\n",
    "hdg = df_ship2['heading']\n",
    "windspeed = df_ship2['windspeed']\n",
    "curspeed = df_ship2['curspeed']\n",
    "truewavedir = df_ship2['truewavedir']\n",
    "truewind = df_ship2['truewinddir']\n",
    "truecurrent = df_ship2['truecurrentdir']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(10, 15))\n",
    "\n",
    "axes[0, 0].hist(oceantemp,bins=25,color='black')\n",
    "axes[0, 0].set_title(r'Air Temperature above Oceans $[K]$', fontsize=fs)\n",
    "axes[0, 0].grid(True,linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "axes[0, 1].hist(surftemp,bins=25,color='black')\n",
    "axes[0, 1].set_title(r'Sea Surface Temperature $[K]$', fontsize=fs)\n",
    "axes[0, 1].grid(True,linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "axes[0, 2].hist(waveperiod,bins=25,color='black')\n",
    "axes[0, 2].set_title(r'Wave Period $[s]$', fontsize=fs)\n",
    "axes[0, 2].grid(True,linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "axes[1, 0].hist(sigwave,bins=25,color='black')\n",
    "axes[1, 0].set_title(r'Significant Wave Height $[m]$', fontsize=fs)\n",
    "axes[1, 0].grid(True,linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "axes[1, 1].hist(draught  ,bins=25,color='black')\n",
    "axes[1, 1].set_title(r'Draught $[m]$', fontsize=fs)\n",
    "axes[1, 1].grid(True,linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "axes[1, 2].hist(truewavedir,bins=25,color='black')\n",
    "axes[1, 2].set_title(r'True Wave Direction $[deg]$', fontsize=fs)\n",
    "axes[1, 2].grid(True,linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "axes[2, 0].hist(cog,bins=25,color='black')\n",
    "axes[2, 0].set_title(r'Course Heading $[deg]$', fontsize=fs)\n",
    "axes[2, 0].grid(True,linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "axes[2, 1].hist(curspeed,bins=25,color='black')\n",
    "axes[2, 1].set_title(r'Current Speed $[m/s]$', fontsize=fs)\n",
    "axes[2, 1].grid(True,linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "axes[2, 2].hist(windspeed,bins=25,color='black')\n",
    "axes[2, 2].set_title(r'Wind Speed $[m/s]$', fontsize=fs)\n",
    "axes[2, 2].grid(True,linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "axes[3, 0].hist(hdg,bins=25,color='black')\n",
    "axes[3, 0].set_title(r'Heading $[deg]$', fontsize=fs)\n",
    "axes[3, 0].grid(True,linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "axes[3, 1].hist(truecurrent,bins=25,color='black')\n",
    "axes[3, 1].set_title(r'True Current Direction $[deg]$', fontsize=fs)\n",
    "axes[3, 1].grid(True,linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "axes[3, 2].hist(truewind,bins=25,color='black')\n",
    "axes[3, 2].set_title(r'True Wind Direction $[deg]$', fontsize=fs)\n",
    "axes[3, 2].grid(True,linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "fig.subplots_adjust(hspace=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ship2['sog'].hist(bins=25,color='black')\n",
    "# Parameter to plot in nice latex fonts\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams.update({\n",
    "\t\"text.usetex\": True,\n",
    "\t\"font.family\": \"serif\",\n",
    "\t\"font.serif\": \"bookman\",\n",
    "\t})\n",
    "plt.grid(linestyle = '--', linewidth = 0.5)\n",
    "plt.xlabel(r\"SOG $[Knots]$\")\n",
    "plt.title(r\"Speed Over Ground (SOG)\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing using KNN so that the Random Forest Regressor may function <br>\n",
    "RFR cannot accept nan values <br>\n",
    "Imputed data is then transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=50)\n",
    "imputer.fit(df_ship2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.transform(df_ship2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ship2tr = pd.DataFrame(X, columns=df_ship2.columns, index=df_ship2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ship2tr.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation of Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_ship2tr.drop(['sog'],axis=1)\n",
    "y_train = df_ship2tr.sog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Amount of the x training dataset is:\",len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling using Random Forest Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model_rfr_ftr = RandomForestRegressor(random_state=42)\n",
    "start_rf = time.time()\n",
    "model_rfr_ftr.fit(x_train,y_train)\n",
    "end_rf = time.time()\n",
    "print(f\"Training time: {end_rf-start_rf:0.4}s \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HPO RFR for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model_rfr_ftr_hpov = RandomForestRegressor(n_estimators = 100,\n",
    "                                            min_samples_split = 2,\n",
    "                                            min_samples_leaf = 1,\n",
    "                                            max_features = 10,\n",
    "                                            max_depth=120,\n",
    "                                            random_state=42)\n",
    "\n",
    "# # Prev HPO: (n_estimators = 900,min_samples_split = 2,min_samples_leaf = 2,# max_features = 9,max_depth=200,random_state=42)\n",
    "\n",
    "start_rfo = time.time()\n",
    "model_rfr_ftr_hpov.fit(x_train,y_train)\n",
    "end_rfo = time.time()\n",
    "print(f\"Training time: {end_rfo-start_rfo:0.4}s \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling using ETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "model_etr = ExtraTreesRegressor(random_state=42)\n",
    "start_et = time.time()\n",
    "model_etr.fit(x_train,y_train)\n",
    "end_et = time.time()\n",
    "print(f\"Training time: {end_et-start_et:0.4}s \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HPO ETR for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "model_etr_hpov = ExtraTreesRegressor(random_state=42,\n",
    "                                n_estimators=800,\n",
    "                                min_samples_split=9,\n",
    "                                min_samples_leaf=1,\n",
    "                                max_features=12,\n",
    "                                max_depth=120,\n",
    "                                )\n",
    "# Prev HPO (random_state=42,n_estimators=600,max_depth=10)\n",
    "\n",
    "start_eto = time.time()\n",
    "model_etr_hpov.fit(x_train,y_train)\n",
    "end_eto = time.time()\n",
    "print(f\"Training time: {end_eto-start_eto:0.4}s\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling using Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model_dtr = DecisionTreeRegressor()\n",
    "start_dtr = time.time()\n",
    "model_dtr.fit(x_train,y_train)\n",
    "end_dtr = time.time()\n",
    "print(f\"Training time: {end_dtr-start_dtr:0.4}s\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HPO DTR for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model_dtr_hpov = DecisionTreeRegressor(min_samples_split=7,\n",
    "                                  min_samples_leaf=10,\n",
    "                                  max_features=12,\n",
    "                                  max_depth=8)\n",
    "# Old HPO (min_samples_split=2,min_samples_leaf=3,max_features=12,max_depth=10)\n",
    "start_dtro = time.time()\n",
    "model_dtr_hpov.fit(x_train,y_train)\n",
    "end_dtro = time.time()\n",
    "print(f\"Training time: {end_dtro-start_dtro:0.4}s\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling using Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "model_mlr = linear_model.LinearRegression()\n",
    "start_mlr = time.time()\n",
    "model_mlr.fit(x_train,y_train)\n",
    "end_mlr = time.time()\n",
    "print(f\"Training time: {end_mlr-start_mlr:0.4}s\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model to local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Saving the model to local directory\n",
    "\n",
    "# filename = 'savemodel_rfr_ftr.sav'\n",
    "# joblib.dump(model_rfr_ftr,filename)\n",
    "\n",
    "# filename = 'savemodel_rfr_ftr_hpov.sav'\n",
    "# joblib.dump(model_rfr_ftr_hpov,filename)\n",
    "\n",
    "# filename = 'savemodel_etr.sav'\n",
    "# joblib.dump(model_etr,filename)\n",
    "\n",
    "# filename = 'savemodel_etr_hpov.sav'\n",
    "# joblib.dump(model_etr_hpov,filename)\n",
    "\n",
    "# filename = 'savemodel_dtr_ftr.sav'\n",
    "# joblib.dump(model_dtr,filename)\n",
    "\n",
    "# filename = 'savemodel_dtr_hpov.sav'\n",
    "# joblib.dump(model_dtr_hpov,filename)\n",
    "\n",
    "# filename = 'savemodel_mlr_ftr.sav'\n",
    "# joblib.dump(model_mlr,filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tree using graphviz, generate 2nd tree in forest (Graphviz must be installed in local computer)\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "dot_data2 = tree.export_graphviz(model_rfr_ftr.estimators_[2], \n",
    "                  feature_names=x_train.columns.values.tolist(),  \n",
    "                #   class_names=class_names,  \n",
    "                  filled=True, rounded=True,  \n",
    "                  special_characters=True,\n",
    "                   out_file=None,\n",
    "                   max_depth=3,\n",
    "                           )\n",
    "\n",
    "display(graphviz.Source(dot_data2))\n",
    "\n",
    "# # Only uncomment when about to generate PNG file, it will create source file that cannot be ignored by git\n",
    "\n",
    "# graph = graphviz.Source(dot_data2)\n",
    "# graph.format = 'png'\n",
    "# graph.render('rf_tree_test_it2',view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 5th tree in forest\n",
    "\n",
    "dot_data5 = tree.export_graphviz(model_rfr_ftr.estimators_[5], \n",
    "                  feature_names=x_train.columns.values.tolist(),  \n",
    "                #   class_names=class_names,  \n",
    "                  filled=True, rounded=True,  \n",
    "                  special_characters=True,\n",
    "                   out_file=None,\n",
    "                   max_depth=3,\n",
    "                           )\n",
    "\n",
    "display(graphviz.Source(dot_data5))\n",
    "\n",
    "# # Only uncomment when about to generate PNG file, it will create source file that cannot be ignored by git\n",
    "\n",
    "# graph = graphviz.Source(dot_data5)\n",
    "# graph.format = 'png'\n",
    "# graph.render('rf_tree_test_it5',view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_importance(model_type):\n",
    "    mod_imp = model_type.feature_importances_\n",
    "    df_mod_imp = pd.DataFrame(mod_imp,index= x_train.columns,columns=[\"Importance\"])\n",
    "    print(df_mod_imp.sort_values(by=['Importance'],ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model_type,names,model_name):\n",
    "\n",
    "    importance = model_type.feature_importances_\n",
    "\n",
    "    #Create arrays from feature importance and feature names\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(5,4))\n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'],color='black')\n",
    "    #Add chart labels\n",
    "    plt.title(f\"Feature Importance of {model_name}\")\n",
    "    plt.grid(linestyle = '--', linewidth = 0.4,axis='x')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.xlim(0,0.7)\n",
    "    plt.ylabel('Feature Names')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_importance(model_rfr_ftr)\n",
    "plot_feature_importance(model_rfr_ftr,x_train.columns,'Random Forest Regressor')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_importance(model_etr)\n",
    "plot_feature_importance(model_etr,x_train.columns,'Extra Tree Regressor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_importance(model_dtr)\n",
    "plot_feature_importance(model_dtr,x_train.columns,'Decicision Tree Regressor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, features_x, labels_y):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    score_r2 = cross_val_score(model,features_x,labels_y,\n",
    "                           scoring='r2',cv=10)\n",
    "    rsquared = score_r2.mean()\n",
    "    stadev_rsquared = score_r2.std()\n",
    "    max_rsquared = score_r2.max()\n",
    "    min_rsquared = score_r2.min()\n",
    "\n",
    "    score_expVar = cross_val_score(model,features_x,labels_y,\n",
    "                           scoring='explained_variance',cv=10)\n",
    "    expVar = score_expVar.mean()\n",
    "    stadev_expVar = score_expVar.std()\n",
    "    max_expVar = score_expVar.max()\n",
    "    min_expVar = score_expVar.min()\n",
    "\n",
    "    score_MAE = cross_val_score(model,features_x,labels_y,\n",
    "                           scoring='neg_mean_absolute_error',cv=10)\n",
    "    MAE = -score_MAE.mean()\n",
    "    stadev_MAE = score_MAE.std()\n",
    "    max_MAE = -score_MAE.max()\n",
    "    min_MAE = -score_MAE.min()\n",
    "\n",
    "    score_MAD = cross_val_score(model,features_x,labels_y,\n",
    "                           scoring='neg_median_absolute_error',cv=10)\n",
    "    MAD = -score_MAD.mean()\n",
    "    stadev_MAD = score_MAD.std()\n",
    "    max_MAD = -score_MAD.max()\n",
    "    min_MAD = -score_MAD.min()\n",
    "\n",
    "\n",
    "\n",
    "    score_RMSE = cross_val_score(model,features_x,labels_y,\n",
    "                           scoring='neg_root_mean_squared_error',cv=10)\n",
    "    RMSE = -score_RMSE.mean()\n",
    "    stadev_RMSE = score_RMSE.std()\n",
    "    max_RMSE = -score_RMSE.max()\n",
    "    min_RMSE = -score_RMSE.min()\n",
    "\n",
    "\n",
    "    print(f\"Model Performance of {model}\")\n",
    "    print(f\"R^2 = {rsquared:0.4f}, std = {stadev_rsquared:0.4f}, max = {max_rsquared:0.4f}, min = {min_rsquared:0.4f}\")\n",
    "    print(f\"explained Variance = {expVar:0.4f}, std = {stadev_expVar:0.4f}, max = {max_expVar:0.4f}, min = {min_expVar:0.4f}\")\n",
    "    print(f\"MAE = {MAE:0.4f}, std = {stadev_MAE:0.4f}, max = {max_MAE:0.4f}, min = {min_MAE:0.4f}\")\n",
    "    print(f\"RMSE = {RMSE:0.4f}, std = {stadev_RMSE:0.4f}, max = {max_RMSE:0.4f}, min = {min_RMSE:0.4f}\")\n",
    "    print(f\"MAD = {MAD:0.4f}, std = {stadev_MAD:0.4f}, max = {max_MAD:0.4f}, min = {min_MAD:0.4f}\\n\")\n",
    "\n",
    "    return score_r2,score_expVar,score_MAE,score_MAD,score_RMSE        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_rf,expVar_rf,MAE_rf,RMSE_rf,MAD_rf = evaluate(model_rfr_ftr,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimised model performance\n",
    "\n",
    "r2_rfo,expVar_rfo,MAE_rfo,RMSE_rfo,MAD_rfo = evaluate(model_rfr_ftr_hpov,x_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of ETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_et,expVar_et,MAE_et,RMSE_et,MAD_et = evaluate(model_etr,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimised model performance \n",
    "\n",
    "r2_eto,expVar_eto,MAE_eto,RMSE_eto,MAD_eto = evaluate(model_etr_hpov,x_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of DTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_dt,expVar_dt,MAE_dt,RMSE_dt,MAD_dt = evaluate(model_dtr,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimised model performance\n",
    "\n",
    "r2_dto,expVar_dto,MAE_dto,RMSE_dto,MAD_dto = evaluate(model_dtr_hpov,x_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of MLR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_mlr,expVar_mlr,MAE_mlr,RMSE_mlr,MAD_mlr = evaluate(model_mlr,x_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter to reset plot properties to default and change the font to tex\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams.update({\n",
    "\t\"text.usetex\": True,\n",
    "\t\"font.family\": \"serif\",\n",
    "\t\"font.serif\": \"bookman\",\n",
    "\t})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for RMSE and Rsquared plots\n",
    "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit ,learning_curve\n",
    "\n",
    "def learn_plotrmse(model,x_data,y_data,model_name):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator = model, X=x_data, y=y_data,\n",
    "                                                        cv=5, train_sizes=np.linspace(0.1, 1.0, 20),\n",
    "                                                        n_jobs=-1,scoring=\"neg_root_mean_squared_error\")\n",
    "\t# Parameter to plot in nice latex fonts\n",
    "    plt.rcParams.update({\n",
    "\t\"text.usetex\": True,\n",
    "\t\"font.family\": \"serif\",\n",
    "\t\"font.serif\": \"bookman\",\n",
    "\t})\n",
    "    #\n",
    "    # Calculate training and test mean and std\n",
    "    #\n",
    "    train_mean = -np.mean(train_scores, axis=1)\n",
    "    train_std = -np.std(train_scores, axis=1)\n",
    "    test_mean = -np.mean(test_scores, axis=1)\n",
    "    test_std = -np.std(test_scores, axis=1)\n",
    "    #\n",
    "    # Plot the learning curve\n",
    "    #\n",
    "    plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label=r'Training Error')\n",
    "    plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "    plt.plot(train_sizes, test_mean, color='green', marker='d', markersize=5, linestyle='--', label=r'Validation Error')\n",
    "    plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "    plt.title(fr'Learning Curve of {model_name}')\n",
    "    plt.xlabel(r'Training Data Size')\n",
    "    plt.ylabel(r'RMSE [knots]')\n",
    "    plt.ylim(0,2)\n",
    "    plt.grid(linestyle = '--', linewidth = 0.5)\n",
    "    plt.legend(loc='lower right')\n",
    "    # plt.show()\n",
    "def learn_plotr2(model,x_data,y_data,model_name):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator = model, X=x_data, y=y_data,\n",
    "                                                        cv=5, train_sizes=np.linspace(0.1, 1.0, 20),\n",
    "                                                        n_jobs=-1,scoring=\"r2\")\n",
    "\t# Parameter to plot in nice latex fonts\n",
    "    plt.rcParams.update({\n",
    "\t\"text.usetex\": True,\n",
    "\t\"font.family\": \"serif\",\n",
    "\t\"font.serif\": \"bookman\",\n",
    "\t})\n",
    "    #\n",
    "    # Calculate training and test mean and std\n",
    "    #\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "    #\n",
    "    # Plot the learning curve\n",
    "    #\n",
    "    plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label=r'Training Score')\n",
    "    plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "    plt.plot(train_sizes, test_mean, color='green', marker='d', markersize=5, linestyle='--', label=r'Validation Score')\n",
    "    plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "    plt.title(fr'Learning Curve of {model_name}')\n",
    "    plt.xlabel(r'Training Data Size')\n",
    "    plt.ylabel(r'Rsquared')\n",
    "    plt.ylim(0.5,1)\n",
    "    plt.grid(linestyle = '--', linewidth = 0.5)\n",
    "    plt.legend(loc='lower right')\n",
    "    # plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding Effect of Hyperparameter optimisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Curve DTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "plt.sca(axes[0])\n",
    "learn_plotrmse(model_dtr,x_train,y_train,'DTR')\n",
    "plt.sca(axes[1])\n",
    "learn_plotrmse(model_dtr_hpov,x_train,y_train,'DTR + HPO')\n",
    "plt.ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "plt.sca(axes[0])\n",
    "learn_plotr2(model_dtr,x_train,y_train,'DTR')\n",
    "plt.sca(axes[1])\n",
    "learn_plotr2(model_dtr_hpov,x_train,y_train,'DTR + HPO')\n",
    "plt.ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Curve RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "plt.sca(axes[0])\n",
    "learn_plotrmse(model_rfr_ftr,x_train,y_train,'RFR')\n",
    "plt.sca(axes[1])\n",
    "learn_plotrmse(model_rfr_ftr_hpov,x_train,y_train,'RFR + HPO')\n",
    "plt.ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "plt.sca(axes[0])\n",
    "learn_plotr2(model_rfr_ftr,x_train,y_train,'RFR')\n",
    "plt.sca(axes[1])\n",
    "learn_plotr2(model_rfr_ftr_hpov,x_train,y_train,'RFR + HPO')\n",
    "plt.ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Curve ETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "plt.sca(axes[0])\n",
    "learn_plotrmse(model_etr,x_train,y_train,'ETR')\n",
    "plt.sca(axes[1])\n",
    "learn_plotrmse(model_etr_hpov,x_train,y_train,'ETR + HPO')\n",
    "plt.ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "plt.sca(axes[0])\n",
    "learn_plotr2(model_etr,x_train,y_train,'ETR')\n",
    "plt.sca(axes[1])\n",
    "learn_plotr2(model_etr_hpov,x_train,y_train,'ETR + HPO')\n",
    "plt.ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box plot for evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "\t\"text.usetex\": True,\n",
    "\t\"font.family\": \"serif\",\n",
    "\t\"font.serif\": \"bookman\",\n",
    "\t})\n",
    "scores = [r2_rf,r2_et,r2_dt,r2_mlr]\n",
    "fig = plt.figure(figsize=(5,3))\n",
    "# Creating axes instance\n",
    "# ax = fig.add_axes([0, 0, 1, 1])\n",
    "fig,ax = plt.subplots()\n",
    "plt.title(\"Test Data Model Performance\")\n",
    "plt.ylabel(\"R-squared\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.yscale('linear')\n",
    "plt.ylim(0.2,1.0)\n",
    "plt.boxplot(scores,showmeans=True)\n",
    "plt.grid(axis='y',linestyle = '--', linewidth = 0.5)\n",
    "ax.set_xticklabels(['RFR', 'ETR',\n",
    "                    'DTR', 'MLR'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_opt = [r2_rf,r2_rfo,r2_et,r2_eto,r2_dt,r2_dto]\n",
    "fig = plt.figure(figsize=(5,3))\n",
    "# Creating axes instance\n",
    "fig,ax = plt.subplots() \n",
    "plt.title(\"Optimized Model on Test Dataset Performance\")\n",
    "plt.ylabel(\"R-squared\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylim(0.2,1.0)\n",
    "plt.yscale('linear')\n",
    "ax.boxplot(scores_opt,showmeans=True)\n",
    "plt.grid(axis='y',linestyle = '--', linewidth = 0.5)\n",
    "ax.set_xticklabels([r'RFR', r'$RFR_{opt}$',\n",
    "                    r'ETR', r'$ETR_{opt}$',\n",
    "                    r'DTR',r'$DTR_{opt}$'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "\t\"text.usetex\": True,\n",
    "\t\"font.family\": \"serif\",\n",
    "\t\"font.serif\": \"bookman\",\n",
    "\t})\n",
    "scores_rmse = [np.abs(RMSE_rf),np.abs(RMSE_et),np.abs(RMSE_dt),np.abs(RMSE_mlr)]\n",
    "fig = plt.figure(figsize=(5,3))\n",
    "# Creating axes instance\n",
    "fig,ax = plt.subplots() \n",
    "plt.title(\"Test Data Model Performance\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylim(0,1.2)\n",
    "plt.yscale('linear')\n",
    "ax.boxplot(scores_rmse,showmeans=True)\n",
    "plt.grid(axis='y',linestyle = '--', linewidth = 0.5)\n",
    "ax.set_xticklabels(['RFR', 'ETR',\n",
    "                    'DTR', 'MLR'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_opt = [-RMSE_rf,-RMSE_rfo,-RMSE_et,-RMSE_eto,-RMSE_dt,-RMSE_dto]\n",
    "fig = plt.figure(figsize=(5,3))\n",
    "# Creating axes instance\n",
    "fig,ax = plt.subplots() \n",
    "plt.title(\"Optimized Model Performance\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.yscale('linear')\n",
    "plt.ylim(0,1.6)\n",
    "ax.boxplot(rmse_opt,showmeans=True)\n",
    "plt.grid(axis='y',linestyle = '--', linewidth = 0.5)\n",
    "ax.set_xticklabels([r'RFR', r'$RFR_{opt}$',\n",
    "                    r'ETR', r'$ETR_{opt}$',\n",
    "                    r'DTR',r'$DTR_{opt}$'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geron1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
